# Nginx 简单入门与配置实例

Nginx 是一款自由的、开源的、高性能的 HTTP 和反向代理 Web 服务器，同时也提供了 IMAP/POP3/SMTP 服务，它的特点是占有内存少，并发能力强。

Nginx 专为性能优化而开发，性能是其最重要的考量，它非常注重效率，能经受高负载的考验，有报告表明，Nginx 能支持高达 50000 个并发连接数。

## 1 基本概念

#### (1) 反向代理

Nginx 不仅可以做反向代理，实现负载均衡，还能用作正向代理来进行上网等功能。

如果把局域网外的 Internet 想象成一个巨大的资源库，则局域网中的客户端要访问 Internet，需要通过代理服务器来访问，这种代理服务器就称为**正向代理**。举个例子，我们直接访问 google.com 是访问不了的，需要在浏览器配置代理服务器，比如 abc.com，通过代理服务器去访问 google.com，也就是说依赖代理服务器进行网络访问，这个过程就叫做**正向代理**。

![正向代理](http://m.qpic.cn/psc?/V10mSDSc0CUQs4/QNsgOSLzUrTyB8UN2gSlSIDXjC.ta35HaQYG2MmwZu9zo42Uts1z*bmZkqxOPbdQ.0ZtDhjdlHIDMRPsXOFrXA!!/b&bo=RgODAUYDgwEDCSw!&rf=viewer_4)

**反向代理：** 客户端对代理是无感知的，因为客户端不需要做任何配置，只需要将请求发送到反向代理服务器，由**反向代理服务器**去选择**目标服务器**，获取数据后再返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实的服务器 IP 地址。

简单来说就是，通过一个反向代理服务器，把客户端的请求转发到不同的目标服务器上。

![反向代理](http://m.qpic.cn/psc?/V10mSDSc0CUQs4/6RAq0V9V8Td2AB7JS6C71O3T5oAwkiyMJkEri*0uwedBEyp9gReuo9d3kUYTzKHX1btqv8D3lRYnFWjpH9wAEYQqeb5AAP*SX*K2PjCkSZU!/b&bo=EAO5ARADuQEDKQw!&rf=viewer_4)

#### (2) 负载均衡

客户端发送多个请求到服务器，服务器处理请求（有可能会与数据库进行交互）后，会将结果返回给客户端。这种请求响应的模式适合于系统业务简单、并发请求相对较少的情况。如果访问量和数据量特别大、系统业务很复杂，这种模式会造成服务器对客户端请求的响应速度变慢，如果并发量特别大的话，还会造成服务器崩溃。

如何解决这个问题呢？

首先我们肯定会想到去升级服务器的物理配置。但是如果服务器的配置已经达到顶级了，还是解决不了这个问题，怎么办呢？这时候就产生了**集群**的概念。

单个服务器满足不了需求的时候，我们可以增加服务器的数量，然后将请求分发到多个服务器上，也就是将负载分发到不同的服务器上，这就是**负载均衡**。

![负载均衡](http://m.qpic.cn/psc?/V10mSDSc0CUQs4/QNsgOSLzUrTyB8UN2gSlSC6TuPiV.n17sgr1*7SbRPxi*mp7mRqNUOrHS2YS7IsoaWIE6hqoyd6boRY*KX*W9w!!/b&bo=igLAAYoCwAEDCSw!&rf=viewer_4)

#### (3) 动静分离

为了加快网站的解析速度，可以使用不同的服务器来解析动态页面和静态页面，从而加快解析的速度，降低原来单个服务器的压力。

![动静分离](http://m.qpic.cn/psc?/V10mSDSc0CUQs4/6RAq0V9V8Td2AB7JS6C71PPyIfxNKXs6qW5g3.ystN8Vwrk*Ju926h08H3kNqnv5wqEuLGq7iXCt6yIN72qPmx.st5XW.KWIkNIcnwrtK2w!/b&bo=NAOtATQDrQEDKQw!&rf=viewer_4)

## 2 安装

这里我们学习的是如何在 Linux 系统中安装 Nginx。

#### (1) 安装步骤

**步骤一：** 使用 Xshell 连接到 Linux 操作系统

**步骤二：** 安装 Nginx 相关的依赖

```shell
yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel
```

**步骤三：** 安装 Nginx

在 Windows 系统中下载安装文件 nginx-1.16.1.tar.gz，cd 到 /usr/src 目录中，把 Windows 中的安装文件拖到命令行处（这种方法我试了一下，失败了，其实可以考虑使用 Xftp），执行命令 `tar -xvf nginx-1.16.1.tar.gz` 解压文件，进入解压之后的目录 nginx-1.16.1，执行命令 `./configure` 进行检查，再执行命令 `make && make install` 进行编译和安装。

也可以 cd 到 /usr/src 目录中，通过命令 `wget http://nginx.org/download/nginx-1.16.1.tar.gz` 来下载安装文件。

安装成功之后，usr/local/nginx/sbin 目录中会有 Nginx 的启动脚本，进入目录后，通过命令 `./nginx` 可以启动 Nginx。通过查看进程命令 `ps -ef | grep nginx` 来查看 Nginx 进程是否启动。

进入 usr/local/nginx/conf 目录，通过命令 `vi nginx.conf` 可以打开 nginx.conf 文件，查看 Nginx 的配置，默认是 80 端口。

#### (2) 设置防火墙

如果外部主机访问不到 80 端口，可能是因为 Linux 系统开启了防火墙，下面有两种方法可以解决这个问题：

**方法一：** 通过命令 `systemctl stop firewalld` 来关闭防火墙

```shell
systemctl status firewalld # 查看防火墙的服务状态
firewall-cmd --state # 查看防火墙的状态
systemctl start firewalld # 开启防火墙
systemctl stop firewalld # 关闭防火墙
```

**方法二：** 通过增加防火墙规则，把 80 端口开放出去

```shell
firewall-cmd --list-all # 查看防火墙规则（开放的端口）
firewall-cmd --permanent --add-port=80/tcp # 开放80端口
firewall-cmd --reload # 重启防火墙
```

## 3 常用命令

使用 Nginx 命令的前提是进入 /usr/local/nginx/sbin 目录。

```shell
./nginx -v # 查看Nginx版本号
./nginx -s stop # 关闭Nginx
./nginx # 启动Nginx
```

如果我们修改了 Nginx 的配置文件 nginx.conf，修改后的配置不会立刻生效，可以重启 Nginx，也可以重新加载 Nginx：

```shell
./nginx -s reload # 重新加载Nginx
```

## 4 配置文件

在目录 /usr/local/nginx/conf 目录中的 nginx.conf 就是 Nginx 的配置文件，通过命令 `vi nginx.conf` 打开配置文件。

Nginx 的配置文件由三部分组成：

#### (1) 全局块

配置文件开始到 events 块之间的部分是**全局块**，主要设置一些影响 Nginx 服务器整体运行的配置指令，包括运行 Nginx 服务器的用户（组）、允许生成的 work process 数、进程 PID 存放路径、日志存放路径和类型、配置文件的引入等。

比如下面的配置，它是表示 Nginx 服务器并发处理服务的关键配置，work_processes 值越大，可以支持的并发处理量就越多，但是会受到硬件、软件等的制约。

```
worker_processes  1;
```

#### (2) events 块

events 块涉及的指令主要影响 Nginx 服务器与用户的网络连接，常用的设置包括是否开启对多 work process 下的网络连接进行序列化、是否允许同时接收多个网络连接、选取哪种事件驱动模型来处理连接请求、每个 word process 可以同时支持的最大连接数等。

这部分配置对 Nginx 的性能影响较大，在实际中应该灵活配置。

比如下面的配置，表示每个 work process 支持的最大连接数为 1024。

```
events {
    worker_connections  1024;
}
```

#### (3) http 块

http 块算是 Nginx 服务器中配置最频繁的部分了，代理、缓存、日志定义等绝大多数功能和第三方模块的配置都在里。http 块包括 **http 全局块**和 **server 块**。

**http 全局块**配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等。

**server 块**和虚拟主机有密切关系（**虚拟主机**从用户角度来看，和一台独立的硬件主机是完全一样的，虚拟主机技术的产生是为了节省互联网服务器硬件成本）。每个 http 块可以包括多个 server 块，而每个 server 块就相当于一个虚拟主机。

每个 **server 块**又分为**全局 server 块**和 **location 块**。

**全局 server 块：** 配置本虚拟主机的监听、名称（IP 别名）等。

**location 块：** 一个 server 块可以配置多个 location 块，主要作用是，基于 Nginx 服务器接收到的请求字符串（比如 server_name/uri-string），对虚拟主机名称（也可以是 IP 别名）之外的字符串（比如前面的 /uri-string）进行匹配，对特定的请求进行处理。另外，这里还可以配置地址定向、数据缓存、应答控制以及许多第三方模块。

```
http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;
    server {
        listen       80;
        server_name  localhost;
        location / {
            root   html;
            index  index.html index.htm;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
}
```

## 5 配置实例

### 5.1 反向代理

#### (1) 配置实例1

我们想实现的效果是，通过浏览器访问 www.123.com，跳转到 Linux 系统中的 Tomcat 服务器主页面。

**步骤一：** 下载 JDK 安装文件 jdk-8u212-linux-x64.tar.gz 和 Tomcat 安装文件 apache-tomcat-7.0.103.tar.gz，使用 Xftp 把安装文件传输到 Linux 系统的 /usr/src 目录中：

```shell
tar -xvf jdk-8u212-linux-x64.tar.gz # 解压
tar -xvf apache-tomcat-7.0.103.tar.gz # 解压
```

**步骤二：** 配置 JDK 环境变量：

```shell
vim /etc/profile # 打开配置文件

# 按i，切换成输入模式，在配置文件尾部添加如下信息，然后按ESC，再输入:wq保存并退出
export JAVA_HOME=/usr/src/jdk1.8.0_212
export CLASSPATH=$:CLASSPATH:$JAVA_HOME/lib/
export PATH=$PATH:$JAVA_HOME/bin

source /etc/profile # 刷新环境配置
java -version #检查是否安装成功
```

**步骤三：** 启动 Tomcat 服务器，默认端口是 8080：

```shell
cd apache-tomcat-7.0.103/
cd bin
./startup.sh # 启动

# 查看日志
cd ..
cd logs
tail -f catalina.out
```

**步骤四：** 在 Windows 系统中通过地址 <http://150.158.107.63:8080> 访问 Tomcat 服务器，检查 Tomcat 服务器是否启动成功。

**步骤五：** 在 Windows 系统中的 C:\Windows\System32\drivers\etc 目录中找到 hosts 文件，用编辑器打开，在文件尾部添加如下的域名和 IP 的对应关系：

```
150.158.107.63 www.123.com
```

再通过命令 `ipconfig /flushdns` 刷新 DNS 缓存。

**步骤六：** 配置 Nginx，实现请求转发（反向代理）：

```bash
server {
  listen       80;
  server_name  150.158.107.63; # 把localhost修改成150.158.107.63
  location / {
    root   html;
    proxy_pass  http://127.0.0.1:8080; # 增加proxy_pass配置
    index  index.html index.htm;
  }
  error_page   500 502 503 504  /50x.html;
  location = /50x.html {
    root   html;
  }
}
```

**步骤七：** 启动 Nginx 进行测试。

#### (2) 配置实例2

我们想实现的效果是，根据访问的路径不同，跳转到不同端口的服务中，比如，Nginx 监听的端口为 9091，访问 <http://127.0.0.1:9001/edu/> 跳转到 127.0.0.1:8080，访问 <http://127.0.0.1:9001/vod/> 跳转到 127.0.0.1:8081。

**步骤一：** 准备两个 Tomcat 服务器，一个使用8080 端口，一个使用 8081 端口。

停掉以前的 Tomcat 服务：

```shell
ps -ef | grep tomcat
kill -9 17796
```

在 /usr/src 目录中新建两个目录 tomcat8080 和 tomcat8081，分别放入 Tomcat 安装文件并且解压。

修改 tomcat8081 目录中的 Tomcat 配置：

```shell
cd apache-tomcat-7.0.103/
cd conf
vim server.xml
```

```xml
<!-- 8005改成8015 -->
<Server port="8015" shutdown="SHUTDOWN">
<!-- 8080改成8081 -->
<Connector port="8081" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" />
```

把两个 Tomcat 服务启起来：

```shell
cd apache-tomcat-7.0.103/
cd bin
./startup.sh
```

**步骤二：** 创建文件夹和测试页面。

在 /usr/src/tomcat8080/apache-tomcat-7.0.103/webapps 目录中新建文件夹 edu，在 edu 文件夹中放一个 a.html 文件：

```html
<h1>8080!</h1>
```

在 /usr/src/tomcat8081/apache-tomcat-7.0.103/webapps 目录中新建文件夹 vod，在 vod 文件夹中放一个 a.html 文件：

```html
<h1>8081!</h1>
```

**步骤三：** 配置 Nginx 反向代理，新增 server 块如下：

```shell
server {
  listen       9001;
  server_name  150.158.107.63;

  location ~ /edu/ {
    proxy_pass  http://127.0.0.1:8080;
  }
  location ~ /vod/ {
    proxy_pass  http://127.0.0.1:8081;
  }
}
```

注意，如果编辑 nginx.conf 文件的时候，意外退出了，这时候再打开这个文件会报错，可以通过命令删除隐藏文件 .nginx.conf.swp：

```shell
rm .nginx.conf.swp
```

**步骤四：** 启动 Nginx 进行测试，访问 <http://150.158.107.63:9001/edu/a.html> 和 <http://150.158.107.63:9001/vod/a.html>，看是否实现了我们想要的效果。

#### (3) location 指令说明

location 指令用于匹配 uri，语法如下：

```
location [ = | ~ | ~* | ^~ ] uri {
  # ...
}
```

指令说明如下：

| 指令 | 描述                                                                                                                                                                          |
| ---- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| =    | uri 不包含正则表达式，要求请求字符串与 URI 严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求                                                                         |
| ~    | uri 包含正则表达式，并且区分大小写                                                                                                                                            |
| ~*   | uri 包含正则表达式，并且不区分大小写                                                                                                                                          |
| ^~   | uri 不包含正则表达式，要求 Nginx 服务器找到标识 uri 和请求字符串匹配度最高的 location 后，立即使用此 location 处理请求，而不再使用 location 块中的正则 uri 和请求字符串做匹配 |

如果 uri 包含正则表达式，则必须要有 ~ 或 ~* 标识。

### 5.2 负载均衡

#### (1) 配置实例

我们想实现的效果是，在客户端浏览器访问 <http://150.158.107.63/edu/a.html>，Nginx 会把请求平均分配到 8080 端口和 8081 端口。

**步骤一：** 准备两个 Tomcat 服务器，一个使用8080 端口，一个使用 8081 端口。

**步骤二：** 创建文件夹和测试页面。

在 /usr/src/tomcat8080/apache-tomcat-7.0.103/webapps 目录和 /usr/src/tomcat8081/apache-tomcat-7.0.103/webapps 目录中都新建文件夹 edu，在 edu 文件夹中都放入 a.html 文件，a.html 中根据不同的端口号写不同的内容：

```html
<h1>8080!</h1>
```

```html
<h1>8081!</h1>
```

**步骤三：** 配置 Nginx，实现负载均衡。

在 http 块中添加负载均衡服务器列表：

```bash
upstream myserver { # myserver是自己取的名字，配置location中的proxy_pass的时候会用到
    server 150.158.107.63:8080;
    server 150.158.107.63:8081;
}
```

修改 http 块中的 server 块：

```bash
server {
  listen       80;
  server_name  150.158.107.63; # 把localhost修改成150.158.107.63
  location / {
    proxy_pass  http://myserver; # 增加proxy_pass配置
    root   html;
    index  index.html index.htm;
  }
  error_page   500 502 503 504  /50x.html;
  location = /50x.html {
    root   html;
  }
}
```

**步骤四：** 启动 Nginx 进行，在浏览器输入 <http://150.158.107.63/edu/a.html> 进行测试。

#### (2) 分配策略

如何把请求分配到不同的服务器，Nginx 提供了几种分配策略：

**轮询：** 这是默认的策略，也就是每个请求按时间顺序逐一分配到不同的后端服务器，如果有服务器 down 掉了，会自动剔除掉这个服务器。

**weight：** weight 代表权重，默认是 1，权重越高，被分配的客户端越多。weight 用来指定轮询几率，它和访问比率成正比，用于后端服务器性能不均的情况。

```
upstream myserver {
    server 150.158.107.63:8080 weight=5;
    server 150.158.107.63:8081 weight=10;
}
```

**ip_hash：** 每个请求根据访问 ip 的 hash 结果进行分配，这样可以让每个访客固定访问一个后端服务器（如果某个 ip 第一次访问的是 8080，那么后面这个 ip 永远只会访问到 8080），可以解决 session 的问题。

```
upstream myserver {
		ip_hash;
    server 150.158.107.63:8080;
    server 150.158.107.63:8081;
}
```

**fair：** 第三方，根据后端服务器的响应时间来分配请求，响应时间短的优先分配。

```
upstream myserver {
    server 150.158.107.63:8080;
    server 150.158.107.63:8081;
    fair;
}
```

### 5.3 动静分离

#### (1) 简介

Nginx 动静分离简单来说就是把动态请求和静态请求分开，不能理解成只是单纯地把动态页面和静态页面物理分离。

我们可以这样做，使用 Nginx 处理静态请求（比如图片等静态资源），使用 Tomcat 处理动态请求（比如请求接口）。

![动静分离](https://wx2.sinaimg.cn/mw690/600a9336gy1gd3wqupqzyj20gn09nq3a.jpg)

**实现动静分离目前有两种方式：**一种方式是纯粹把静态文件放在独立的服务器上，是目前主流的方式；另一种方式是把动态文件和静态文件混合在一起发布，通过 Nginx 来分开。

#### (2) 配置步骤

**步骤一：** 在 Linux 根目录中新建文件夹 zoe，在 zoe 文件夹中新建 www 文件夹和 image 文件夹。在 www 文件夹中放一个 .html 文件，在 image 文件夹中放一张图片。

**步骤二：** 配置 Nginx，实现静态资源请求。

```
location /www/ {
    root   /zoe/;
    index  index.html index.htm;
}

location /image/ {
    root   /zoe/;
    autoindex  on;
}
```

**步骤三：** 重启 Nginx，在浏览器输入地址 <http://150.158.107.63/image/avatar.jpg> 和 <http://150.158.107.63/www/a.html> 进行测试。

因为上面配置了 `autoindex  on`，所以在浏览器输入地址 <http://150.158.107.63/image/>，会把服务器中 zoe/image 目录中的所有文件列出来。

**补充：** 通过在 location 中配置 expires 参数，可以设置浏览器缓存过期时间。比如给一个资源设定一个过期时间，在过期（浏览器自身会确认是否过期）之前，浏览器请求这个资源，会比对服务器中该文件最后更新时间有没有变化，如果没有变化，就不会从服务器抓取，返回状态码 304，如果有变化，则会从服务器重新下载，返回状态码 200。这种方法会减少服务器的请求和流量，减轻服务器的压力，适合不经常变动的资源，对于经常更新的文件，不建议使用这种方法。

## 6 配置高可用集群

很多请求是通过 Nginx 转发的，所以如果 Nginx 宕机了，我们的请求就无法正常响应。为了解决这个问题，需要配置 Nginx 高可用，图示如下：

![高可用](https://wx3.sinaimg.cn/mw690/600a9336gy1gd43hw5cwzj20uc0b1wez.jpg)

**高可用配置（主从配置）步骤如下：**

**步骤一：** 准备两个服务器。我准备了两个腾讯云服务器 129.211.151.223 和 150.158.107.63。当然也可以使用 VMware 创建两个虚拟机。

**步骤二：** 在两个服务器上都安装 Nginx 和 keepalived。

Nginx 的安装步骤上面写过了。

通过命令 `yum install -y keepalived` 来安装 keepalived，通过命令 `rpm -q -a keepalived` 来检查 keepalived 是否安装成功。keepalived 安装之后，在目录 /etc 中会生成一个 keepalived 文件夹，在这个文件夹中的 keepalived.conf 文件就是 keepalived 的配置文件。

**步骤三：** 修改 /ect/keepalived/keepalived.conf 配置文件：

```
! Configuration File for keepalived

global_defs {
   notification_email {
     acassen@firewall.loc
     failover@firewall.loc
     sysadmin@firewall.loc
   }
   notification_email_from Alexandre.Cassen@firewall.loc
   smtp_server 150.158.107.63
   smtp_connect_timeout 30
   router_id ZOE_CENTOS # ZOE_CENTOS是主机名字，通过主机名字可以访问到服务器，这个名字是在/etc/hosts文件中添加的，在hosts文件末尾添加：127.0.0.1  ZOE_CENTOS
}

# 配置脚本，用于检测Nginx是否在正常运行
vrrp_script chk_http_port {
  script "/usr/local/src/nginx_check.sh" # 脚本路径
  interval 2 # 脚本执行的间隔
  weight 2 # 设置当前服务器的权重
}

# 配置虚拟IP
vrrp_instance VI_1 {
    state MASTER    # 如果是备份服务器，改成BACKUP
    interface eth0  # 网卡，通过ifconfig命令可以查看
    virtual_router_id 51 # 主、备机virtual_router_id必须相同
    priority 100    # 优先级，主、备机取不同的优先级，主机值较大，备机值较小
    advert_int 1    # 每隔1秒检测一下服务器是否在正常运行
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        150.158.107.66   # 虚拟IP，可以配置多个，如果使用的云服务器的话，这个虚拟IP不能随便设置
    }
}
```

**步骤四：** 在目录中 /usr/local/src 中添加检测脚本 nginx_check.sh，用于检测 Nginx 是否在正常运行：

```
#!/bin/bash
A=`ps -C nginx --no-header |wc -l`
if [ $A -eq 0 ];then
    /usr/local/nginx/sbin/nginx
    sleep 2
    if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then
        killall keepalived
    fi
fi
```

**步骤五：** 把两个服务器上的 Nginx 和 keepalived 都启动起来，进行测试。

keepalived 需要通过命令 `systemctl start keepalived.service` 来启动，start 换成 stop 就是停止 keepalived。如果是 CentOS 6，需要使用命令 `service keepalived start` 来启动 keepalived。

通过命令 `ip a` 可以查看该服务器绑定的虚拟 IP。

在浏览器地址栏输入 150.158.107.66 进行测试。

## 7 原理

**查看 Nginx 进程：**

![master&worker](https://wx3.sinaimg.cn/mw690/600a9336gy1gd47el5lrkj20fp01r746.jpg)

**master 进程和 worker 进程：**

![master&worker](https://wx3.sinaimg.cn/mw690/600a9336gy1gd47egsnf7j20mh0dl75z.jpg)

**worker 进程：**

![worker](https://wx2.sinaimg.cn/mw690/600a9336gy1gd47evhi2ij20m40akmzi.jpg)

**一个 master 多个 worker 机制有什么好处呢？**

利于 Nginx 进行热部署操作，也就是命令 `./nginx -s reload`。

每个 worker 是独立的进程，如果其中一个 worker 出现了问题，不会影响其它的 worker，它们还可以继续对请求进行争抢，不会造成服务中断。而且独立的进程，不需要加锁，便于编程以及问题查找。

**设置多少个 worker 才合适呢？**

Nginx 同 redis 类似，都采用了 io 多路复用机制，每个 worker 都是一个独立的进程，每个进程里只有一个主线程，通过异步非阻塞的方式来处理请求，即使是千上万个请求也不在话下。每个 worker 的线程可以把一个 cpu 的性能发挥到极致。**所以 worker 数和服务器的 cpu 数相等是最为适宜的。**设少了会浪费 cpu，设多了会造成 cpu 频繁切换上下文带来损耗。

**发送一个请求，会占用 work 几个 work_connection 连接数？**

如果只是请求静态资源，那么会占用 2 个连接数。如果不但要请求静态资源还要请求接口（Tomcat 服务），那么会占用 4 个连接数。

**Nginx 有一个 master 和 4 个 worker，每个 worker 支持的最大连接数是 1024，那么这个 Nginx 服务器支持的最大并发数是多少？**

```
4 * 1024 / 2 = 2048 # 普通的静态访问，支持的最大并发数
4 * 1024 / 4 = 1024 # HTTP作为反向代理，支持的最大并发数
```
