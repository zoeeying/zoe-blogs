# K8s 学习笔记

Kubernetes 简称 K8s，是一个开源的，用于自动部署、扩展和管理容器化应用的容器编排系统。

在 Kubernetes 中，所有的容器均在 Pod 中运行，一个 Pod 可以承载一个或者多个相关的容器。同一个 Pod 中的容器会部署在同一个物理机器上并且能够共享资源。一个 Pod 也可以包含 0 个或者多个磁盘卷组（volumes），这些卷组将会以目录的形式提供给一个容器，或者被所有 Pod 中的容器共享。

Kubernetes 主要处理：服务发现和负载均衡，存储编排，自动部署和回滚，自动完成装箱计算，自我修复，密钥与配置管理。

Kubernetes 工作方式：Kubernetes Cluster = N Master Node + N Worker Node。

## 1 组件架构

一个 Kubernetes 集群是由一组被称作节点（node）的机器组成， 这些节点上会运行由 Kubernetes 所管理的容器化应用，且每个集群至少有一个工作节点。

Kubernetes 集群的组件：

![image-20220729223708805](C:\Users\叙叙\AppData\Roaming\Typora\typora-user-images\image-20220729223708805.png)

### 控制平面组件（Control Plane Components）

控制平面组件会为集群做出全局决策。控制平面组件可以在集群中的任何节点上运行， 但是为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件，并且不会在此计算机上运行用户容器。

#### kube-apiserver

API 服务器是 Kubernetes 控制平面的前端，负责公开 Kubernetes API，并负责处理接受请求的工作。Kubernetes API 服务器的主要实现是 kube-apiserver。可以通过部署多个实例来对 kube-apiserver 进行扩缩。

#### etcd

etcd 是兼顾一致性与高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。

#### kube-scheduler

kube-scheduler  负责监视新创建的、未指定运行节点的 Pods，并选择节点来让 Pod 在上面运行。调度决策考虑的因素包括单个 Pod 及 Pods 集合的资源需求、软硬件及策略约束、亲和性及反亲和性规范、数据位置、工作负载间的干扰及最后时限。

#### kube-controller-manager

kube-controller-manager 负责运行控制器进程。从逻辑上讲，每个控制器都是一个单独的进程，但是为了降低复杂性，它们都被编译到同一个可执行文件，并在同一个进程中运行。

这些控制器包括：

1、节点控制器（Node Controller），负责在节点出现故障时进行通知和响应；

2、任务控制器（Job Controller），监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成；

3、端点控制器（Endpoints Controller），填充端点（Endpoints）对象，即加入 Service 与 Pod；

4、服务帐户和令牌控制器（Service Account & Token Controllers），为新的命名空间创建默认帐户和 API 访问令牌。

#### cloud-controller-manager

cloud-controller-manager 是指嵌入特定云的控制逻辑的控制平面组件。

### Node 组件

节点组件会在每个节点上运行，负责维护运行的 Pod 并提供 Kubernetes 运行环境。

#### kubelet

kebelet 会在集群中每个节点上运行，它接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态，且是健康的。kubelet 不会管理不是由 Kubernetes 创建的容器。

#### kube-proxy

kube-proxy 维护节点上的一些网络规则，这些网络规则会允许从集群内部或外部的网络会话与 Pod 进行网络通信。如果操作系统提供了可用的数据包过滤层，则 kube-proxy 会通过它来实现网络规则，否则，kube-proxy 仅做流量转发。

#### 容器运行时

容器运行环境是负责运行容器的软件，比如 Docker。

## 2 集群部署

![image-20220731235938224](C:\Users\叙叙\AppData\Roaming\Typora\typora-user-images\image-20220731235938224.png)

## 3 环境准备

K8s 实战，至少需要准备三台服务器。

### 基础环境

设置主机名，需要注意的是，集群中的主机名不能重复：

```shell
hostnamectl set-hostname k8s-master
hostnamectl set-hostname k8s-node-01
hostnamectl set-hostname k8s-node-02
```

禁用交换分区，Swap 必须都是 0：

![image-20220806153401028](../images/image-20220806153401028.png)

允许 iptables 检查桥接流量：

```shell
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
br_netfilter
EOF

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sudo sysctl --system
```

### 安装 Docker

```shell
# 安装yum工具
yum install -y yum-utils

# 配置Docker的yum源
yum-config-manager \
--add-repo \
https://download.docker.com/linux/centos/docker-ce.repo

# 安装指定版本Docker
yum install -y docker-ce-20.10.7 docker-ce-cli-20.10.7 containerd.io-1.4.6

# 开机启动Docker
systemctl enable docker --now

# 配置镜像加速器以及生产环境核心配置
mkdir -p /etc/docker
tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": ["https://3vorqqsx.mirror.aliyuncs.com"],
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF
systemctl daemon-reload
systemctl restart docker
```

### 安装 kubelet、kubeadm、kubectl

```shell
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
   http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF

sudo yum install -y kubelet-1.20.9 kubeadm-1.20.9 kubectl-1.20.9 --disableexcludes=kubernetes
sudo systemctl enable --now kubelet
```

### 下载必要的镜像

```shell
sudo tee ./images.sh <<-'EOF'
#!/bin/bash
images=(
kube-apiserver:v1.20.9
kube-proxy:v1.20.9
kube-controller-manager:v1.20.9
kube-scheduler:v1.20.9
coredns:1.7.0
etcd:3.4.13-0
pause:3.2
)
for imageName in ${images[@]} ; do
docker pull registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/$imageName
done
EOF
```

```shell
chmod +x ./images.sh && ./images.sh
```

shell 脚本中下载的镜像版本是固定的，且使用的是雷丰阳老师提供的的阿里云镜像仓库。

将本地镜像推送到阿里云镜像仓库：

```shell
docker tag 5ef66b403f4f registry.cn-hangzhou.aliyuncs.com/zoe_k8s_images/calico-node:v3.20.0
docker push registry.cn-hangzhou.aliyuncs.com/zoe_k8s_images/calico-node:v3.20.0
```

### 初始化 Master 节点

在所有机器上添加主节点域名映射，并且需要能 ping 通 cluster-endpoint：

```shell
echo "172.31.0.1 cluster-endpoint" >> /etc/hosts
ping cluster-endpoint
```

`172.31.0.1` 是主节点的私有 IP。

主节点初始化：

```shell
kubeadm init \
--apiserver-advertise-address=172.31.0.1 \
--control-plane-endpoint=cluster-endpoint \
--image-repository=registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images \
--kubernetes-version=v1.20.9 \
--service-cidr=10.96.0.0/16 \
--pod-network-cidr=192.168.0.0/16
```

主节点初始化时，所有网络范围不能重叠。

主节点初始化成功提示：

```shell
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of control-plane nodes by copying certificate authorities
and service account keys on each node and then running the following as root:

  kubeadm join cluster-endpoint:6443 --token lutxr2.kd9w7lxb95gdm8es \
    --discovery-token-ca-cert-hash sha256:a16a588bf802fe432035e908c4992d0e7042df433343bfea2d14818aa7e8c14c \
    --control-plane 

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join cluster-endpoint:6443 --token lutxr2.kd9w7lxb95gdm8es \
    --discovery-token-ca-cert-hash sha256:a16a588bf802fe432035e908c4992d0e7042df433343bfea2d14818aa7e8c14c
```

执行上面成功提示中的命令：

```shell
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

export KUBECONFIG=/etc/kubernetes/admin.conf
```

```shell
# 下载网络组件Calico的配置文件并安装，版本是v3.20
curl https://docs.projectcalico.org/v3.20/manifests/calico.yaml -O
kubectl apply -f calico.yaml

# 下载最新版本Calico配置文件
curl https://docs.projectcalico.org/manifests/calico.yaml -O
```

**注意事项：**

**(1) Calico 版本必须与 K8s 版本相匹配**

注意，Calico 版本必须与 K8s 版本相匹配，否则会导致部署失败。

可以在 Calico 官网查看不同 Calico 版本对应的 K8s 版本：

```shell
https://projectcalico.docs.tigera.io/archive/v3.20/getting-started/kubernetes/requirements
```

v3.20 会对应到最新的小版本，比如截止 2022/8/7，最新的小版本是 v3.20.6。

但是本项目使用的固定小版本是 v3.20.0。

**(2) 重新初始化**

如果集群尚未完全正常运行，或者有问题，可以重新初始化：

```shell
kubeadm reset
rm -rf $HOME/.kube /etc/kubernetes
```

### Worker 节点

对于 Worker 节点，执行下面的命令，加入集群：

```shell
kubeadm join cluster-endpoint:6443 --token lutxr2.kd9w7lxb95gdm8es \
    --discovery-token-ca-cert-hash sha256:a16a588bf802fe432035e908c4992d0e7042df433343bfea2d14818aa7e8c14c
```

成功加入集群后，在 Master 节点上执行命令，查看所有节点、Pods 状态：

![image-20220807192202519](../images/image-20220807192202519.png)

![image-20220807203225451](../images/image-20220807203225451.png)

Worker 节点加入集群需要令牌，初始化 Master 节点生成的令牌有效期是 24 小时，如果令牌过期了，可以在 Master 节点上生成新的令牌：

```shell
kubeadm token create --print-join-command
```

### k8s 常用命令

```shell
# 查看集群所有节点
kubectl get nodes

# 根据配置文件，给集群创建资源
kubectl apply -f xxx.yaml

# 查看集群中部署的应用
kubectl get pods -A

# describe
kubectl describe pod kube-proxy-5vj7k -n kube-system
```

运行中的应用在 Docker 中叫容器，在 K8s 中叫 Pod。

### 部署 Dashboard

```shell
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.3.1/aio/deploy/recommended.yaml
```

如下图，把 `type: ClusterIP` 改成 `type: NodePort`：

```shell
kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard
```

![image-20220807221004655](../images/image-20220807221004655.png)

上面的操作会把 K8s Dashboard 页面的端口号暴露到机器上。

```shell
kubectl get svc -A |grep kubernetes-dashboard
```

![image-20220807221937799](../images/image-20220807221937799.png)

最后，访问 `https://集群任意节点公网IP:32524`，即可打开 Dashboard 页面：

![image-20220807222951190](../images/image-20220807222951190.png)

登录 K8s Dashboard，需要创建访问账号。

首先，需要准备一个 Yaml 文件：

```yaml
# dashboard-adminuser.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
```

```shell
kubectl apply -f dashboard-adminuser.yaml

# 获取访问令牌
kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath="{.secrets[0].name}") -o go-template="{{.data.token | base64decode}}"
```

把生成的令牌复制到页面中，即可登录 K8s Dashboard。











